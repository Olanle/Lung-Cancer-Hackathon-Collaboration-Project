{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I99xfQLFWAc7",
        "outputId": "29cad019-0dd3-457d-d7ea-6f9ea498d1e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "#5acab72028e81c5fbbddde9eb6202108\n",
        "od.download(\"https://www.kaggle.com/datasets/xiaopengzhang12/lung-cancer-mri-images\")"
      ],
      "metadata": {
        "id": "ylclEKz8WEUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a519fd43-79a6-4f3d-ab5a-f7877969c3fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: Olanle\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/xiaopengzhang12/lung-cancer-mri-images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data paths (adjust if necessary)\n",
        "data_dir = \"//content/lung-cancer-mri-images/lung_cancer_MRI_dataset/train\"\n",
        "data_dir2 = \"//content/lung-cancer-mri-images/lung_cancer_MRI_dataset/validate\"\n",
        "categories = [\"cancer\", \"no_cancer\"] #lung_aca\", \"lung_n\", \"lung_scc\"]\n",
        "\n",
        "# Image preprocessing parameters\n",
        "img_size = (128, 128)  # Resize images to a consistent size\n",
        "batch_size = 32\n",
        "\n",
        "# Image data generation\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, img_size)\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image"
      ],
      "metadata": {
        "id": "uj1UiJLfWEvd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = []\n",
        "labels = []\n",
        "for category_index, category in enumerate(categories):\n",
        "    path = os.path.join(data_dir, category)\n",
        "    for img in os.listdir(path):\n",
        "        try:\n",
        "            img_array = preprocess_image(os.path.join(path, img))\n",
        "            image_data.append(img_array)\n",
        "            labels.append(category_index)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image: {img}, Error: {e}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "image_data = np.array(image_data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "ideEMh4vWFEX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = []\n",
        "labels = []\n",
        "for category_index, category in enumerate(categories):\n",
        "    # Process images from both directories in one loop\n",
        "    for data_dir in [data_dir, data_dir2]:  # Iterate through both directories\n",
        "        path = os.path.join(data_dir, category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = preprocess_image(os.path.join(path, img))\n",
        "                image_data.append(img_array)\n",
        "                labels.append(category_index)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing image: {img}, Error: {e}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "image_data = np.array(image_data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "jtxJuCgC1q7g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode labels\n",
        "labels = tf.keras.utils.to_categorical(labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1ZpxFJEUWFZz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5), # Added dropout for regularization\n",
        "    layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JB5bmZWjWFr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8061ecc6-2bc4-4e5b-95e8-88bfac043a77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WX3bizsLVu9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6064e041-a160-45e4-99a8-57523c2faf33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 69ms/step - accuracy: 0.6674 - loss: 0.6183 - val_accuracy: 0.7598 - val_loss: 0.4269\n",
            "Epoch 2/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8004 - loss: 0.3805 - val_accuracy: 0.7904 - val_loss: 0.3781\n",
            "Epoch 3/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8196 - loss: 0.3367 - val_accuracy: 0.8166 - val_loss: 0.3631\n",
            "Epoch 4/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8398 - loss: 0.3009 - val_accuracy: 0.7948 - val_loss: 0.3600\n",
            "Epoch 5/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8413 - loss: 0.3010 - val_accuracy: 0.8122 - val_loss: 0.3670\n",
            "Epoch 6/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8569 - loss: 0.2615 - val_accuracy: 0.7773 - val_loss: 0.4105\n",
            "Epoch 7/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8613 - loss: 0.2515 - val_accuracy: 0.8384 - val_loss: 0.3554\n",
            "Epoch 8/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8799 - loss: 0.2192 - val_accuracy: 0.8210 - val_loss: 0.3816\n",
            "Epoch 9/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9172 - loss: 0.1829 - val_accuracy: 0.8472 - val_loss: 0.3664\n",
            "Epoch 10/10\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9229 - loss: 0.1597 - val_accuracy: 0.8515 - val_loss: 0.4247\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79895cf5a150>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.1) # Reduced epochs and added validation_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9KaJmaylwhk",
        "outputId": "90b1eca2-be4a-4f2e-8eef-d19cb51c6a76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8521 - loss: 0.4505\n",
            "Test Loss: 0.3862\n",
            "Test Accuracy: 0.8497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8_cdyxglxNY",
        "outputId": "4471b951-0a41-47fe-a886-e39d0b3026ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report and confusion matrix\n",
        "print(classification_report(y_true_classes, y_pred_classes))\n",
        "print(confusion_matrix(y_true_classes, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX9QKsvPl3VU",
        "outputId": "184a58e6-c776-4e61-c0f3-c36f918bded0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.82      0.88       372\n",
            "           1       0.73      0.90      0.81       200\n",
            "\n",
            "    accuracy                           0.85       572\n",
            "   macro avg       0.84      0.86      0.84       572\n",
            "weighted avg       0.87      0.85      0.85       572\n",
            "\n",
            "[[306  66]\n",
            " [ 20 180]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zxrq5Wy8PnNd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}